# Image Caption Generation
December 2016 - This project and the project materials are built with 3 other excellent teammates; Safa Messaoud, Ankit Rai and Tarek Elgamal.

### Summary
In this project, we built a pipeline that consists of two models: The first model, Show and Tell (Im2Txt) [1], generates a caption from a given image. The second model, Txt2Im [2], produces an image from a given caption. In addition to training and implementing these two models independently, by combining them, we were also able to compare a given image with the pipeline-generated one and comment on the information conveyed by a caption of just a few words. 

*Obviously, it is not expected to obtain a perfect match between these two images. If not impossible, it would take much more computational power, data and manpower for exquisite modeling than available to us. However, the futuristic idea of perfect reconstruction is very exciting. Imagine storing images as text, taking up a tiny fraction of memory or bandwidth, and then generating them from those "captions" as necessary.*

Details of the project can be found [in this presentation](Show_and_Tell_Presentation.pdf) and [in this report](Show_and_Tell_Project_report.pdf)
